# Global Memory Coalescing
[Back to Table of Contents](../../Readme.md) | [Previous: GPU Memory Hierarchy](3.GPU-memory-hierarchy.md) | **[Next: Shared Memory Programming](5.shared-memory-intro.md)**

## Understanding Memory Coalescing

Global memory coalescing is a technique used in GPU programming to optimize memory access patterns for better performance. Coalesced memory accesses are those that efficiently utilize the global memory bandwidth by grouping multiple memory requests into a single transaction. This is especially important in CUDA programming, where the way threads access memory can significantly impact the performance of the application.

### Coalesced Memory Access

When multiple threads access consecutive memory addresses within an aligned block, the memory controller can combine these requests into a single transaction. In the context of CUDA, this transaction occurs within a **burst section**, typically a 128-byte aligned block. If 32 threads (a warp) are requesting data from global memory and all requests fall within this 128-byte burst section, the accesses are coalesced. This results in fewer transactions and better utilization of the memory bandwidth.

### Uncoalesced Memory Access

Uncoalesced accesses occur when the threads access scattered memory locations that are not within the same burst section (i.e., 128-byte aligned block). This can happen if:

- Threads access memory in a non-linear pattern.
- The stride of the access pattern is high, meaning threads are not accessing consecutive elements.

For example, if threads access elements with a high stride (e.g., every other element), it results in multiple memory transactions instead of a single coalesced transaction. As a result, performance suffers due to increased latency and reduced memory bandwidth utilization.

In the worst case, if each of the 32 threads in a warp accesses elements in different 128-byte blocks, the memory controller must handle 32 separate transactions. This drastically reduces performance because of the high overhead of managing multiple transactions and inefficient memory usage.

### Identifying Coalesced vs. Uncoalesced Access in CUDA Code

To determine whether memory access is coalesced or uncoalesced, examine the following:

**Stride of Access**: For each global memory reference, check the stride with regard to the linearized thread index (usually just `threadIdx.x`). 
   - **A stride of zero or one indicates coalesced access,** leading to better performance.
   - A high stride suggests uncoalesced access, which is inefficient.


### Example: 
```c
__global__ void mmkernel( float* A, float* B, float* C,
int N, int M, int P )
{
    int i = blockIdx.x*32 + threadIdx.x;
    int j = blockIdx.y;
    float sum = 0.0;
    for( int k = 0; k < P; ++k )
        sum += B[M*k+i] * C[P*j+k];
    A[M*j+i] = sum; // A[M*i+j] = sum; 
}
```
Let's explore all the memory accesses above code and Identify if the memory accesses are coalesced or not:
#### B[M*k+i]
  - We need to calculate the memory stride with respect to tx. To do so let's consider tx = 0 and tx = 1 and compute the stride. 
    - **Important Note:** as all the threads with in a warp execute the same instructions, at each point of time they will have the same blockIdx.x\*32, j = blockIdx.y, and k values.
    - if tx == 0, then idx0 = M\*k+i = M\*k + blockIdx.x\*32
    - if tx == 1, then idx1 = M\*k+i = M\*k + blockIdx.x\*32 + 1
    - so the stride =  idx1 - idx0 = (M\*k + blockIdx.x\*32 + 1) - (M\*k + blockIdx.x\*32) = 1 therefore the memory access is **coalesced** due to stride = 1.

#### C[P*j+k]
  - P, j, and k are the same for all threads of the warp as they execute the same instructions, at each cycle.
  - if tx == 0, then idx0 = P\*j+k = P\*(blockIdx.y) + k
  - if tx == 1, then idx1 = P\*j+k = P\*(blockIdx.y) + k
  - so the stride =  idx1 - idx0 = (P\*(blockIdx.y) + k) - (P\*(blockIdx.y) + k) = 0 therefore the memory access is **coalesced** due to stride = 0.

#### A[M*j+i]
  - M, j are the same for all threads of the warp as they execute the same instructions, at each cycle.
  - if tx == 0, then idx0 = M\*j+i = M\*j + blockIdx.x\*32
  - if tx == 1, then idx1 = M\*j+i = M\*j + blockIdx.x\*32 + 1
  - so the stride =  idx1 - idx0 = (M\*j + blockIdx.x\*32 + 1) - (M\*j + blockIdx.x\*32) = 1 therefore the memory access is **coalesced** due to stride = 1.

#### A[M*i+j]
  - M, j are the same for all threads of the warp as they execute the same instructions, at each cycle.
  - if tx == 0, then idx0 = M\*i+j = M\*(blockIdx.x*32 + threadIdx.x) + j
  - if tx == 1, then idx1 = M\*j+i = M\*(blockIdx.x*32 + threadIdx.x + **1**) + j
  - so the stride =  idx1 - idx0 = M\*(blockIdx.x*32 + threadIdx.x + **1**) + M\*(blockIdx.x*32 + threadIdx.x) + j = M therefore the memory access is **uncoalesced** due to stride = M.

[Back to Table of Contents](../../Readme.md) | [Previous: GPU Memory Hierarchy](3.GPU-memory-hierarchy.md) | **[Next: Shared Memory Programming](5.shared-memory-intro.md)**
